{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1oWKGpoS7pMp0bxWAg89qCkS0EFR-dQos",
      "authorship_tag": "ABX9TyP4KOHENOzjbUzr6biOfEt4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZerXXX0/CV-handwring-recognition-for-digit/blob/main/MNIST_USPS_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8CDiSY_k7Y59"
      },
      "outputs": [],
      "source": [
        "# Used for unpickling byte stream of python objects on file system/disk\n",
        "import pickle\n",
        "# Used for decompressing .gzip files from file system/disk\n",
        "import gzip\n",
        "# Used for array operations\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading MNIST Dataset"
      ],
      "metadata": {
        "id": "5CItPygH7e6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Opening and decompressing .gzip file\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/dataset/mnist.pkl.gz'\n",
        "f = gzip.open(filename, 'rb')\n",
        "\n",
        "# Unpickling .pkl file saved as byte stream on disk to python objects\n",
        "trainingData, validationData, testingData = pickle.load(f, encoding='latin1')\n",
        "f.close()\n",
        "\n",
        "# Training feature vectors and training target extracted from trainingData (target represented using one-hot format)\n",
        "trainingTarget = np.array([1 if  trainingData[1][i] == t else 0  for i in range(len(trainingData[1])) for t in range(10)]).reshape(-1,10)\n",
        "trainingData = trainingData[0]\n",
        "\n",
        "# Validation feature vectors and validation target extracted from validationData\n",
        "validationTarget = validationData[1]\n",
        "validationData = validationData[0]\n",
        "\n",
        "# Testing feature vectors and testing target extracted from testingData\n",
        "testingTarget = testingData[1]\n",
        "testingData = testingData[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq7-HVMt7b5g",
        "outputId": "53d4507e-e687-4b61-8fd8-26511125b447"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading USPS Dataset"
      ],
      "metadata": {
        "id": "saRNnAVT7j7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to open image in file system/disk\n",
        "from PIL import Image\n",
        "# Used to navigate to required directory in the file system\n",
        "import os\n",
        "# Used to convert image data to array\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7m-_hTP77hU-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USPSMat  = []\n",
        "USPSTar  = []\n",
        "curPath  = '/content/drive/MyDrive/Colab Notebooks/dataset/USPSdata/USPSdata/Numerals'\n",
        "savedImg = []\n",
        "\n",
        "\n",
        "# Navigate to the 10 folders containing images for 10 labels\n",
        "for j in range(0,10):\n",
        "    curFolderPath = curPath + '/' + str(j)\n",
        "    imgs =  os.listdir(curFolderPath)\n",
        "    for img in imgs:\n",
        "        curImg = curFolderPath + '/' + img\n",
        "        if curImg[-3:] == 'png':\n",
        "\n",
        "            # Open image resize it, and save image array as well as labels in 2 lists\n",
        "            img = Image.open(curImg,'r')\n",
        "            img = img.resize((28, 28))\n",
        "            savedImg = img\n",
        "            imgdata = (255-np.array(img.getdata()))/255\n",
        "            USPSMat.append(imgdata)\n",
        "            USPSTar.append(j)"
      ],
      "metadata": {
        "id": "OHySQpsU7ryP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks"
      ],
      "metadata": {
        "id": "nyurEmjW7uVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "\n",
        "#DNN\n",
        "num_classes = len(trainingTarget[0])\n",
        "DNNclassifier = Sequential()\n",
        "DNNclassifier.add(Dense(units=200, activation='relu', input_shape=(len(trainingData[0]),)))\n",
        "DNNclassifier.add(Dropout(0.2))\n",
        "DNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "DNNclassifier.add(Dropout(0.2))\n",
        "# DNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "# DNNclassifier.add(Dropout(0.2))\n",
        "DNNclassifier.add(Dense(units=num_classes, activation='softmax'))\n",
        "DNNclassifier.compile(optimizer='Adamax', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = DNNclassifier.fit(trainingData, trainingTarget, batch_size=128, epochs=100,\n",
        "verbose=False,validation_data=(validationData, keras.utils.to_categorical(validationTarget, num_classes)))"
      ],
      "metadata": {
        "id": "B3QrhOHv7-Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "loss,valAccuracy = DNNclassifier.evaluate(validationData, keras.utils.to_categorical(validationTarget, num_classes), verbose=False)\n",
        "loss,testAccuracy = DNNclassifier.evaluate(testingData, keras.utils.to_categorical(testingTarget, num_classes), verbose=False)\n",
        "loss,testUSPSAccuracy = DNNclassifier.evaluate(np.array(USPSMat), keras.utils.to_categorical(USPSTar, num_classes), verbose=False)\n",
        "dnnMNISTPrediction = np.argmax(DNNclassifier.predict(testingData), axis=1)\n",
        "dnnUSPSPrediction = np.argmax(DNNclassifier.predict(np.array(USPSMat)), axis=1)\n",
        "\n",
        "print ('---------------DNN----------------\\n')\n",
        "print('Validation accuracy    = ', valAccuracy*100)\n",
        "print('MNIST Testing accuracy = ', testAccuracy*100)\n",
        "print('USPS Testing accuracy  = ', testUSPSAccuracy*100,'\"\\n\"')\n",
        "print(\"\\nMNIST Confusion Matrix: \\n\\n\",confusion_matrix(testingTarget, dnnMNISTPrediction))\n",
        "print(\"\\nUSPS Confusion Matrix: \\n\\n\",confusion_matrix(USPSTar, dnnUSPSPrediction))"
      ],
      "metadata": {
        "id": "7UrfkQY48Afn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matplotlib package is used for plotting graphs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Outputs training accuracy and loss against epochs\n",
        "fig2, ax2=plt.subplots(figsize=(23,8))\n",
        "ax2.plot(history.history['accuracy'])\n",
        "ax2.set(xlabel='Number of Epochs', ylabel='Training Accuracy')\n",
        "ax2.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pJn7YIoi8EuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "CNNclassifier = Sequential()\n",
        "CNNclassifier.add(Conv2D(20, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "CNNclassifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "CNNclassifier.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "CNNclassifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "CNNclassifier.add(Flatten())\n",
        "CNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "CNNclassifier.add(Dropout(0.2))\n",
        "CNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "CNNclassifier.add(Dropout(0.2))\n",
        "CNNclassifier.add(Dense(units=num_classes, activation='softmax'))\n",
        "CNNclassifier.compile(optimizer='Adamax', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = CNNclassifier.fit(trainingData.reshape(-1, 28, 28, 1), trainingTarget, batch_size=128, epochs=100,\n",
        "verbose=True,validation_data=(validationData.reshape(-1, 28, 28, 1), keras.utils.to_categorical(validationTarget, num_classes)))"
      ],
      "metadata": {
        "id": "yxXjbpta8IKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss,valAccuracy = CNNclassifier.evaluate(validationData.reshape(-1, 28, 28, 1), keras.utils.to_categorical(validationTarget, num_classes), verbose=False)\n",
        "loss,testAccuracy = CNNclassifier.evaluate(testingData.reshape(-1, 28, 28, 1), keras.utils.to_categorical(testingTarget, num_classes), verbose=False)\n",
        "loss,testUSPSAccuracy = CNNclassifier.evaluate(np.array(USPSMat).reshape(-1, 28, 28, 1), keras.utils.to_categorical(USPSTar, num_classes), verbose=False)\n",
        "cnnMNISTPrediction = np.argmax(CNNclassifier.predict(testingData.reshape(-1, 28, 28, 1)), axis=1)\n",
        "cnnUSPSPrediction = np.argmax(CNNclassifier.predict(np.array(USPSMat).reshape(-1, 28, 28, 1)), axis=1)\n",
        "\n",
        "print ('---------------CNN----------------\\n')\n",
        "print('Validation accuracy    = ', valAccuracy*100)\n",
        "print('MNIST Testing accuracy = ', testAccuracy*100)\n",
        "print('USPS Testing accuracy  = ', testUSPSAccuracy*100,\"\\n\")\n",
        "print(\"\\nMNIST Confusion Matrix: \\n\\n\",confusion_matrix(testingTarget, cnnMNISTPrediction))\n",
        "print(\"\\nUSPS Confusion Matrix: \\n\\n\",confusion_matrix(USPSTar, cnnUSPSPrediction))"
      ],
      "metadata": {
        "id": "TXujXJE_8JDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matplotlib package is used for plotting graphs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Outputs training accuracy and loss against epochs\n",
        "fig2, ax2=plt.subplots(figsize=(23,8))\n",
        "ax2.plot(history.history['accuracy'])\n",
        "ax2.set(xlabel='Number of Epochs', ylabel='Training Accuracy')\n",
        "ax2.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sgsJPFUj8MS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "import keras\n",
        "\n",
        "# RNN\n",
        "\n",
        "num_classes = len(trainingTarget[0])  # Number of classes for classification\n",
        "timesteps = 28  # Number of timesteps in the sequence\n",
        "features = 28  # Number of features in each timestep\n",
        "\n",
        "# LSTM-based model\n",
        "RNNclassifier = Sequential()\n",
        "RNNclassifier.add(LSTM(units=200, activation='tanh', return_sequences=True, input_shape=(timesteps, features)))\n",
        "RNNclassifier.add(Dropout(0.2))\n",
        "RNNclassifier.add(LSTM(units=200, activation='tanh'))\n",
        "RNNclassifier.add(Dropout(0.2))\n",
        "RNNclassifier.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "RNNclassifier.compile(optimizer='Adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape trainingData to match the expected input shape (samples, timesteps, features)\n",
        "trainingDataRNN = trainingData.reshape(-1, timesteps, features)\n",
        "\n",
        "# Training the model\n",
        "history = RNNclassifier.fit(\n",
        "    trainingDataRNN, # Pass the reshaped training data\n",
        "    trainingTarget,\n",
        "    batch_size=128,\n",
        "    epochs=100,\n",
        "    verbose=False,\n",
        "    validation_data=(validationData.reshape(-1, timesteps, features), keras.utils.to_categorical(validationTarget, num_classes))\n",
        ")"
      ],
      "metadata": {
        "id": "Rg0iLKq6m1N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Reshaping data for RNN input (samples, timesteps, features)\n",
        "validationDataRNN = validationData.reshape(-1, timesteps, features)\n",
        "testingDataRNN = testingData.reshape(-1, timesteps, features)\n",
        "USPSDataRNN = np.array(USPSMat).reshape(-1, timesteps, features)\n",
        "\n",
        "# Evaluate the RNN model\n",
        "loss, valAccuracy = RNNclassifier.evaluate(validationDataRNN, keras.utils.to_categorical(validationTarget, num_classes), verbose=False)\n",
        "loss, testAccuracy = RNNclassifier.evaluate(testingDataRNN, keras.utils.to_categorical(testingTarget, num_classes), verbose=False)\n",
        "loss, testUSPSAccuracy = RNNclassifier.evaluate(USPSDataRNN, keras.utils.to_categorical(USPSTar, num_classes), verbose=False)\n",
        "\n",
        "# Predict using the RNN model\n",
        "rnnMNISTPrediction = np.argmax(RNNclassifier.predict(testingDataRNN), axis=1)\n",
        "rnnUSPSPrediction = np.argmax(RNNclassifier.predict(USPSDataRNN), axis=1)\n",
        "\n",
        "# Print results\n",
        "print('---------------RNN (LSTM)----------------\\n')\n",
        "print('Validation accuracy    = ', valAccuracy * 100)\n",
        "print('MNIST Testing accuracy = ', testAccuracy * 100)\n",
        "print('USPS Testing accuracy  = ', testUSPSAccuracy * 100, \"\\n\")\n",
        "print(\"\\nMNIST Confusion Matrix: \\n\\n\", confusion_matrix(testingTarget, rnnMNISTPrediction))\n",
        "print(\"\\nUSPS Confusion Matrix: \\n\\n\", confusion_matrix(USPSTar, rnnUSPSPrediction))\n"
      ],
      "metadata": {
        "id": "JwjqqBbjWiVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matplotlib package is used for plotting graphs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Outputs training accuracy and loss against epochs\n",
        "fig2, ax2=plt.subplots(figsize=(23,8))\n",
        "ax2.plot(history.history['accuracy'])\n",
        "ax2.set(xlabel='Number of Epochs', ylabel='Training Accuracy')\n",
        "ax2.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6T0ahYyeW271"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZFNQmHioWIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}