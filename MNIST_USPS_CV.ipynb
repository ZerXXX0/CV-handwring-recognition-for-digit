{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8CDiSY_k7Y59"
      },
      "outputs": [],
      "source": [
        "# Used for unpickling byte stream of python objects on file system/disk\n",
        "import pickle\n",
        "# Used for decompressing .gzip files from file system/disk\n",
        "import gzip\n",
        "# Used for array operations\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading MNIST Dataset"
      ],
      "metadata": {
        "id": "5CItPygH7e6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Opening and decompressing .gzip file\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/dataset/mnist.pkl.gz'\n",
        "f = gzip.open(filename, 'rb')\n",
        "\n",
        "# Unpickling .pkl file saved as byte stream on disk to python objects\n",
        "trainingData, validationData, testingData = pickle.load(f, encoding='latin1')\n",
        "f.close()\n",
        "\n",
        "# Training feature vectors and training target extracted from trainingData (target represented using one-hot format)\n",
        "trainingTarget = np.array([1 if  trainingData[1][i] == t else 0  for i in range(len(trainingData[1])) for t in range(10)]).reshape(-1,10)\n",
        "trainingData = trainingData[0]\n",
        "\n",
        "# Validation feature vectors and validation target extracted from validationData\n",
        "validationTarget = validationData[1]\n",
        "validationData = validationData[0]\n",
        "\n",
        "# Testing feature vectors and testing target extracted from testingData\n",
        "testingTarget = testingData[1]\n",
        "testingData = testingData[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq7-HVMt7b5g",
        "outputId": "fa256487-1b45-4b39-ebc5-a680fb5b1108"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading USPS Dataset"
      ],
      "metadata": {
        "id": "saRNnAVT7j7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Used to open image in file system/disk\n",
        "from PIL import Image\n",
        "# Used to navigate to required directory in the file system\n",
        "import os\n",
        "# Used to convert image data to array\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7m-_hTP77hU-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USPSMat  = []\n",
        "USPSTar  = []\n",
        "curPath  = '/content/drive/MyDrive/Colab Notebooks/dataset/USPSdata/USPSdata/Numerals'\n",
        "savedImg = []\n",
        "\n",
        "# Navigate to the 10 folders containing images for 10 labels\n",
        "for j in range(0,10):\n",
        "    curFolderPath = curPath + '/' + str(j)\n",
        "    imgs =  os.listdir(curFolderPath)\n",
        "    for img in imgs:\n",
        "        curImg = curFolderPath + '/' + img\n",
        "        if curImg[-3:] == 'png':\n",
        "\n",
        "            # Open image resize it, and save image array as well as labels in 2 lists\n",
        "            img = Image.open(curImg,'r')\n",
        "            img = img.resize((28, 28))\n",
        "            savedImg = img\n",
        "            imgdata = (255-np.array(img.getdata()))/255\n",
        "            USPSMat.append(imgdata)\n",
        "            USPSTar.append(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "OHySQpsU7ryP",
        "outputId": "c1a34120-cfdb-4340-bb58-4e5e55ec6a08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/drive/MyDrive/Colab Notebooks/dataset/USPSdata.zip/USPSdata/Numerals/0'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0d76f1c198e2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcurFolderPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurFolderPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcurImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurFolderPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/Colab Notebooks/dataset/USPSdata.zip/USPSdata/Numerals/0'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Networks"
      ],
      "metadata": {
        "id": "nyurEmjW7uVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DNN\n",
        "num_classes = len(trainingTarget[0])\n",
        "DNNclassifier = Sequential()\n",
        "DNNclassifier.add(Dense(units=200, activation='relu', input_shape=(len(trainingData[0]),)))\n",
        "DNNclassifier.add(Dropout(0.2))\n",
        "DNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "DNNclassifier.add(Dropout(0.2))\n",
        "# DNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "# DNNclassifier.add(Dropout(0.2))\n",
        "DNNclassifier.add(Dense(units=num_classes, activation='softmax'))\n",
        "DNNclassifier.compile(optimizer='Adamax', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = DNNclassifier.fit(trainingData, trainingTarget, batch_size=128, epochs=100,\n",
        "verbose=False,validation_data=(validationData, keras.utils.to_categorical(validationTarget, num_classes)))"
      ],
      "metadata": {
        "id": "B3QrhOHv7-Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss,valAccuracy = DNNclassifier.evaluate(validationData, keras.utils.to_categorical(validationTarget, num_classes), verbose=False)\n",
        "loss,testAccuracy = DNNclassifier.evaluate(testingData, keras.utils.to_categorical(testingTarget, num_classes), verbose=False)\n",
        "loss,testUSPSAccuracy = DNNclassifier.evaluate(np.array(USPSMat), keras.utils.to_categorical(USPSTar, num_classes), verbose=False)\n",
        "dnnMNISTPrediction = np.argmax(DNNclassifier.predict(testingData), axis=1)\n",
        "dnnUSPSPrediction = np.argmax(DNNclassifier.predict(np.array(USPSMat)), axis=1)\n",
        "\n",
        "print ('---------------DNN----------------\\n')\n",
        "print('Validation accuracy    = ', valAccuracy*100)\n",
        "print('MNIST Testing accuracy = ', testAccuracy*100)\n",
        "print('USPS Testing accuracy  = ', testUSPSAccuracy*100,'\"\\n\"')\n",
        "print(\"\\nMNIST Confusion Matrix: \\n\\n\",confusion_matrix(testingTarget, dnnMNISTPrediction))\n",
        "print(\"\\nUSPS Confusion Matrix: \\n\\n\",confusion_matrix(USPSTar, dnnUSPSPrediction))"
      ],
      "metadata": {
        "id": "7UrfkQY48Afn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matplotlib package is used for plotting graphs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Outputs training accuracy and loss against epochs\n",
        "fig2, ax2=plt.subplots(figsize=(23,8))\n",
        "ax2.plot(history.history['acc'])\n",
        "ax2.set(xlabel='Number of Epochs', ylabel='Training Accuracy')\n",
        "ax2.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pJn7YIoi8EuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "CNNclassifier = Sequential()\n",
        "CNNclassifier.add(Conv2D(20, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "CNNclassifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "CNNclassifier.add(Conv2D(20, (3, 3), activation='relu'))\n",
        "CNNclassifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "CNNclassifier.add(Flatten())\n",
        "CNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "CNNclassifier.add(Dropout(0.2))\n",
        "CNNclassifier.add(Dense(units=200, activation='relu'))\n",
        "CNNclassifier.add(Dropout(0.2))\n",
        "CNNclassifier.add(Dense(units=num_classes, activation='softmax'))\n",
        "CNNclassifier.compile(optimizer='Adamax', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "history = CNNclassifier.fit(trainingData.reshape(-1, 28, 28, 1), trainingTarget, batch_size=128, epochs=10,\n",
        "verbose=True,validation_data=(validationData.reshape(-1, 28, 28, 1), keras.utils.to_categorical(validationTarget, num_classes)))"
      ],
      "metadata": {
        "id": "yxXjbpta8IKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss,valAccuracy = CNNclassifier.evaluate(validationData.reshape(-1, 28, 28, 1), keras.utils.to_categorical(validationTarget, num_classes), verbose=False)\n",
        "loss,testAccuracy = CNNclassifier.evaluate(testingData.reshape(-1, 28, 28, 1), keras.utils.to_categorical(testingTarget, num_classes), verbose=False)\n",
        "loss,testUSPSAccuracy = CNNclassifier.evaluate(np.array(USPSMat).reshape(-1, 28, 28, 1), keras.utils.to_categorical(USPSTar, num_classes), verbose=False)\n",
        "cnnMNISTPrediction = np.argmax(CNNclassifier.predict(testingData.reshape(-1, 28, 28, 1)), axis=1)\n",
        "cnnUSPSPrediction = np.argmax(CNNclassifier.predict(np.array(USPSMat).reshape(-1, 28, 28, 1)), axis=1)\n",
        "\n",
        "print ('---------------CNN----------------\\n')\n",
        "print('Validation accuracy    = ', valAccuracy*100)\n",
        "print('MNIST Testing accuracy = ', testAccuracy*100)\n",
        "print('USPS Testing accuracy  = ', testUSPSAccuracy*100,\"\\n\")\n",
        "print(\"\\nMNIST Confusion Matrix: \\n\\n\",confusion_matrix(testingTarget, cnnMNISTPrediction))\n",
        "print(\"\\nUSPS Confusion Matrix: \\n\\n\",confusion_matrix(USPSTar, cnnUSPSPrediction))"
      ],
      "metadata": {
        "id": "TXujXJE_8JDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matplotlib package is used for plotting graphs\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# Outputs training accuracy and loss against epochs\n",
        "fig2, ax2=plt.subplots(figsize=(23,8))\n",
        "ax2.plot(history.history['acc'])\n",
        "ax2.set(xlabel='Number of Epochs', ylabel='Training Accuracy')\n",
        "ax2.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sgsJPFUj8MS_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}